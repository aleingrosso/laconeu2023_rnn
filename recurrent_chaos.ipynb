{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4919f5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c539f1",
   "metadata": {},
   "source": [
    "# Dynamics of random recurrent networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5062c15",
   "metadata": {},
   "source": [
    "We will simulate the dynamics of a Sompolinsky Crisanti Sommers (SCS) model\n",
    "\n",
    "$$\n",
    "\\dot{x}_{i}=-x_{i}+\\sum_{j}J_{ij}\\phi\\left(x_{j}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d7ccae",
   "metadata": {},
   "source": [
    "## Init network connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f90b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set size and gain\n",
    "N = 100\n",
    "g = 1.5\n",
    "\n",
    "# generate random coupling matrix\n",
    "J = g * np.random.randn(N, N) / np.sqrt(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851fc60b",
   "metadata": {},
   "source": [
    "Given the symmetry of the function $\\phi$ the network has a trivial $x_i=0$ fixed point.\n",
    "\n",
    "Recall that the dynamics of small perturbations $\\delta x_i = x_i - x^\\star_i$ is generally controlled by the jacobian:\n",
    "\n",
    "$$\n",
    "\\dot{\\delta x}_{i}=-\\delta x_{i}+\\sum_{j}J_{ij}\\phi^{'}\\left(x_{j}^{*}\\right)\\delta x_{j}\n",
    "$$\n",
    "\n",
    "In this case $\\phi^{'}\\left(0\\right) = 1$, so the eigenvalues of $J$ directly control stability. In matrix notation:\n",
    "\n",
    "$$\n",
    "\\dot{\\delta x}=\\left(-1+J\\right)\\delta x\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e3a629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect eigenvalues\n",
    "eigs = np.linalg.eigvals(J)\n",
    "# get eigenvalue with maximal real part\n",
    "argmaxeig = np.argmax(np.real(eigs))\n",
    "maxeig = eigs[argmaxeig]\n",
    "\n",
    "plt.plot(np.real(eigs), np.imag(eigs), '.');\n",
    "plt.plot(np.real(maxeig), np.imag(maxeig), 'o', color='red');\n",
    "plt.plot(np.real(maxeig), -np.imag(maxeig), 'o', color='red');\n",
    "\n",
    "# draw expected eig border\n",
    "thetas = np.linspace(0, 2*np.pi, 50)\n",
    "plt.plot(g * np.cos(thetas), g * np.sin(thetas), ':', color='gray');\n",
    "\n",
    "plt.vlines(x=1, ymin=-g, ymax=g, ls='--', color='gray', alpha=0.5)\n",
    "\n",
    "plt.xlabel('Re($\\lambda$)');\n",
    "plt.ylabel('Im($\\lambda$)');\n",
    "\n",
    "# check linear stability\n",
    "if np.real(maxeig) < 1.:\n",
    "    print(\"The zero fixed point is stable.\")\n",
    "else:\n",
    "    print(\"The zero fixed point is unstable!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7baba7",
   "metadata": {},
   "source": [
    "## Run network dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ef94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set total simulation time and integration time-step\n",
    "T = 1000\n",
    "dt = 0.1\n",
    "titot = int(T / dt)\n",
    "\n",
    "xs = np.empty((titot, N)) # allocate records\n",
    "x = 0.1 * np.random.randn(N) # set random initial condition\n",
    "for ti in range(titot):\n",
    "    h = J @ np.tanh(x) # compute incoming current\n",
    "    x = (1. - dt) * x + dt * h # update network state\n",
    "    xs[ti] = x # record network state\n",
    "\n",
    "# plot activity record\n",
    "upto = -1\n",
    "plt.plot(xs[:upto,:5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7862c619",
   "metadata": {},
   "source": [
    "## Inspect dimensionality of activations: PCA in three different ways"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a0ea1f",
   "metadata": {},
   "source": [
    "Dimensionality of the chaotic attractor can be measured in different ways using dynamical systems theory.\n",
    "\n",
    "PCA is a common tool neuroscientists use to estimate and reduce dimensionality of measurements. One can use such tool to provide a linear estimation of dimensionality of trajectories in random rate networks.\n",
    "\n",
    "A common measure of dimensionality uses a normalized participatio of singular values. Equivalently, given the inter-neuron covariance matrix\n",
    "\n",
    "$$\n",
    "C_{ij}=\\left\\langle \\left(x_{i}-\\left\\langle x_{i}\\right\\rangle \\right)\\left(x_{j}-\\left\\langle x_{j}\\right\\rangle \\right)\\right\\rangle \n",
    "$$\n",
    "\n",
    "with eigenvalues $\\lambda_i$, one computes:\n",
    "\n",
    "$$\n",
    "d=\\frac{\\left(\\sum_{i=1}^{N}\\lambda_{i}\\right)^{2}}{\\sum_{i=1}^{N}\\lambda_{i}^{2}}\n",
    "$$\n",
    "\n",
    "This quantity will be of order N for roughly equally contributing PCA components and and order 1 when only a small fraction of directions in $x$ space contribute to the total variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f374ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca with a little help from your friends: using scikit learn\n",
    "pca = PCA().fit(xs)\n",
    "pca_variance_scikit = pca.explained_variance_\n",
    "\n",
    "\n",
    "# PCA on your own: computing SVD decomposition of data matrix\n",
    "s = np.linalg.svd(xs, compute_uv=False)\n",
    "pca_variance_svd = s**2 / len(xs)\n",
    "\n",
    "\n",
    "# PCA on your own - reprise: eigenvalues of the covariance matrix\n",
    "C = xs.T @ xs / len(xs)\n",
    "pca_variance_covariance = np.linalg.eigvalsh(C)[::-1]\n",
    "\n",
    "\n",
    "# plot the three values and hope the curves are all the same\n",
    "plt.plot(pca_variance_scikit, '-', label='PCA scikit');\n",
    "plt.plot(pca_variance_svd, '--', label='PCA svd')\n",
    "plt.plot(pca_variance_covariance, ':', label='PCA covariance');\n",
    "\n",
    "plt.legend();\n",
    "\n",
    "dim_pca = pca_variance_covariance.sum()**2 / (pca_variance_covariance**2).sum()\n",
    "print(\"PCA dimensionality estimate:\", dim_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10910ec",
   "metadata": {},
   "source": [
    "# Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb4b428",
   "metadata": {},
   "source": [
    "1. How does the dimensionality change as a function of the variance $g^2$? Wrap the simulator and the dimensionality analysis in a function and run it for different valus of g...can you reproduce Fig. 4 of https://arxiv.org/abs/2006.02427?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed8e20f",
   "metadata": {},
   "source": [
    "2. What happens to chaotic dynamics when you drive a recurrent network with some inputs? Take inspiration from this classic work https://journals.aps.org/pre/abstract/10.1103/PhysRevE.82.011903 and try to stimulate a network with a sine wave."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e73c06",
   "metadata": {},
   "source": [
    "3. What happens to chaos in a rate network composed of Excitatory and Inhibitory populations? Can you reproduce Fig. 2 in https://journals.aps.org/prx/abstract/10.1103/PhysRevX.5.041030?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
